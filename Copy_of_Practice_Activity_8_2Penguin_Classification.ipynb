{
  "cells": [
    {
      "attachments": {},
      "cell_type": "raw",
      "metadata": {
        "id": "TxbDFsJARAMD"
      },
      "source": [
        "---\n",
        "title: \"8.2 Penguin Classification - Eldridge\"\n",
        "format:\n",
        "  html:\n",
        "    theme: darkly\n",
        "embed-resources: true\n",
        "---"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Palmer Penguins Modeling\n",
        "\n",
        "Import the Palmer Penguins dataset and print out the first few rows.\n",
        "\n",
        "Suppose we want to predict `species` using the other variables in the dataset.\n",
        "\n",
        "**Dummify** all variables that require this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QV2uolyOQ65C",
        "outputId": "fde8398e-fe4b-499b-e717-c5b56fc61299"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting palmerpenguins\n",
            "  Downloading palmerpenguins-0.1.4-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from palmerpenguins) (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from palmerpenguins) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->palmerpenguins) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->palmerpenguins) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->palmerpenguins) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->palmerpenguins) (1.16.0)\n",
            "Downloading palmerpenguins-0.1.4-py3-none-any.whl (17 kB)\n",
            "Installing collected packages: palmerpenguins\n",
            "Successfully installed palmerpenguins-0.1.4\n"
          ]
        }
      ],
      "source": [
        "!pip install palmerpenguins\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "x1t5Ra6aoMFh"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from palmerpenguins import load_penguins\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f97kqm4WrhG8",
        "outputId": "06174052-e690-4a39-9742-ccdda7f4ad10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 1.0\n"
          ]
        }
      ],
      "source": [
        "penguins = load_penguins().dropna()\n",
        "\n",
        "penguins['gentoo'] = penguins['species'] == \"Gentoo\"\n",
        "\n",
        "features = penguins.drop(columns=['gentoo'])\n",
        "target = penguins['gentoo']\n",
        "\n",
        "categorical_features = ['species', 'island', 'sex']\n",
        "numeric_features = features.drop(columns=categorical_features).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('preprocessor', preprocessor),\n",
        "    ('logistic_regression', LogisticRegression(max_iter=200))\n",
        "])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "train_accuracy1 = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy1)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HecNBVAnRHod"
      },
      "source": [
        "Let's use the other variables to predict `species`. Prepare your data and fit the following models on the entire dataset:\n",
        "\n",
        "* Two kNN models (for different values of K)\n",
        "* Two decision tree models (for different complexities of trees)\n",
        "\n",
        "Compute the following, for each of your models, on test data. Keep in mind that you may need to stratify your creation of the training and test data.\n",
        "\n",
        "* Confusion matrix\n",
        "* Overall Accuracy\n",
        "* Precision, Recall, AUC, and F1-score for each species\n",
        "\n",
        "Create one ROC plot for the species of your choice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sZKRp69Z0ZBs",
        "outputId": "349ea50d-9422-4e71-990b-567d92fe0ade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9887218045112782\n"
          ]
        }
      ],
      "source": [
        "penguins = load_penguins().dropna()\n",
        "\n",
        "features = penguins.drop(columns=['species'])\n",
        "target = penguins['species']\n",
        "\n",
        "\n",
        "categorical_features = ['island', 'sex']\n",
        "numeric_features = features.drop(columns=categorical_features).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('knn', KNeighborsClassifier(n_neighbors= 3))\n",
        "    ])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "train_accuracy2 = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U1onRGJQR8T_",
        "outputId": "a1d36b6f-8fd0-4390-8e2c-132541c9d5c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training Accuracy: 0.9962406015037594\n"
          ]
        }
      ],
      "source": [
        "penguins = load_penguins().dropna()\n",
        "\n",
        "features = penguins.drop(columns=['species'])\n",
        "target = penguins['species']\n",
        "\n",
        "\n",
        "categorical_features = ['island', 'sex']\n",
        "numeric_features = features.drop(columns=categorical_features).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "\n",
        "pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('knn', KNeighborsClassifier(n_neighbors= 15))\n",
        "    ])\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "pipeline.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = pipeline.predict(X_train)\n",
        "train_accuracy3 = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "print(\"Training Accuracy:\", train_accuracy3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRxtmeoI1gEL",
        "outputId": "b1a5b84c-9dc6-40a4-fea1-5b14bbe7a51f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Decision Tree Model with max_depth=3\n",
            "Training Accuracy: 0.981203007518797\n",
            "Test Accuracy: 0.9701492537313433\n",
            "\n",
            "Decision Tree Model with max_depth=5\n",
            "Training Accuracy: 1.0\n",
            "Test Accuracy: 0.9850746268656716\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from palmerpenguins import load_penguins\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "penguins = load_penguins().dropna()\n",
        "\n",
        "features = penguins.drop(columns=['species'])\n",
        "target = penguins['species']\n",
        "\n",
        "categorical_features = ['island', 'sex']\n",
        "numeric_features = features.drop(columns=categorical_features).columns.tolist()\n",
        "\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', StandardScaler(), numeric_features),\n",
        "        ('cat', OneHotEncoder(drop='first'), categorical_features)\n",
        "    ]\n",
        ")\n",
        "\n",
        "tree_depths = [3, 5]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size=0.2, random_state=42)\n",
        "\n",
        "for depth in tree_depths:\n",
        "    pipeline = Pipeline([\n",
        "        ('preprocessor', preprocessor),\n",
        "        ('decision_tree', DecisionTreeClassifier(max_depth=depth, random_state=42))\n",
        "    ])\n",
        "\n",
        "    pipeline.fit(X_train, y_train)\n",
        "\n",
        "    y_train_pred = pipeline.predict(X_train)\n",
        "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
        "\n",
        "    y_test_pred = pipeline.predict(X_test)\n",
        "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
        "\n",
        "    print(f\"Decision Tree Model with max_depth={depth}\")\n",
        "    print(f\"Training Accuracy: {train_accuracy}\")\n",
        "    print(f\"Test Accuracy: {test_accuracy}\\n\")\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
